{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrUscPSebP1v"
      },
      "source": [
        "## Task 5.2.1 - Brute-Force Hyperparameter Search\n",
        "\n",
        "* Implement a brute-force search function that finds the best parameter combination for a given model. **(RESULT)**\n",
        "* Test your implementation on the following problems:\n",
        "    - 1) A `SVM` model on the two moons problem. **(RESULT)**\n",
        "    - 2) A `LinearRegression` model with Ridge regularization on the `California Housing Dataset`. **(RESULT)**\n",
        "\n",
        "Feel free to use `sklearn`'s model implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_X5Oz6UOhMhh"
      },
      "outputs": [],
      "source": [
        "# Useful imports\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dEL5XQ1dbP1w"
      },
      "outputs": [],
      "source": [
        "# You might check for the following hyperparameter ranges:\n",
        "\n",
        "svm_params = {\n",
        "    'C': [0.1, 1.0, 10.0, 100.0],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "\n",
        "ridge_params = {\n",
        "    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr']\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTwcyJTZAJNq"
      },
      "source": [
        "# Building Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o3_FguLTlsMT"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "def brute_force_search(model, params, task, X_train, y_train, X_test, y_test):\n",
        "  mydict ={}\n",
        "  paramdict={}\n",
        "  combinations = list(itertools.product(*list(params.values())))\n",
        "  for combination in combinations:\n",
        "    for key, value in zip(params.keys(), combination):\n",
        "      paramdict[key]=value\n",
        "    mymodel= model(**paramdict)\n",
        "    mymodel.fit(X_train, y_train)\n",
        "    if task ==\"Classification\":\n",
        "      score = accuracy_score(y_test, mymodel.predict(X_test))\n",
        "    else:\n",
        "      score = mean_squared_error(y_test, mymodel.predict(X_test))\n",
        "    mydict[tuple(combination)] = score\n",
        "  if task ==\"Classification\":\n",
        "      best_combination = max(mydict, key=lambda k: mydict[k])\n",
        "  else:\n",
        "    best_combination = min(mydict, key=lambda k: mydict[k])\n",
        "  return best_combination\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-OpbdMt7Uhb"
      },
      "source": [
        "This function should have the task type passed to make sure the the correct metric is being calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdWZHcS8AMeF"
      },
      "source": [
        "# Exploring different ways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YRGIiron6vop"
      },
      "outputs": [],
      "source": [
        "# combination = []\n",
        "# for i in range(len(svm_params['C'])):\n",
        "#     for j in range(len(svm_params['kernel'])):\n",
        "#         for k in range(len(svm_params['gamma'])):\n",
        "#             combination.append((i,j,k))\n",
        "# print(combination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJXGYVYY6yYO"
      },
      "source": [
        "We have thought of getting the combinations using just loops but wouldn't have been generic for any model because who says i have 3 parameters only , so 3 loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KD1ryYWQ9ox8"
      },
      "outputs": [],
      "source": [
        "# def brute_force_search(model, params, task, X_train, y_train, X_test, y_test):\n",
        "#   mydict ={}\n",
        "#   paramdict={}\n",
        "#   sizes = [len(v) for v in params.values()]\n",
        "#   grids = np.meshgrid(*list(params.values()), indexing='ij')\n",
        "#   combinations = zip(*(g.flatten() for g in grids))\n",
        "\n",
        "#   for combination in combinations:\n",
        "\n",
        "#     for key, value in zip(params.keys(), combination):\n",
        "#       paramdict[key]=value\n",
        "#     mymodel= model(**paramdict)\n",
        "#     mymodel.fit(X_train, y_train)\n",
        "#     if task ==\"Classification\":\n",
        "#       score = accuracy_score(y_test, mymodel.predict(X_test))\n",
        "#     else:\n",
        "#       score = mean_squared_error(y_test, mymodel.predict(X_test))\n",
        "#     mydict[tuple(combination)] = score\n",
        "#   if task ==\"Classification\":\n",
        "#       best_combination = max(mydict, key=lambda k: mydict[k])\n",
        "#   else:\n",
        "#     best_combination = min(mydict, key=lambda k: mydict[k])\n",
        "#   return best_combination\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S3PhuzV_lEz"
      },
      "source": [
        "Another way to find the different combinations of parameters that we explored is through the np.meshgrid function (uncomment if you want to test). we explored it in case itertools is not allowed to be used although nothing has been mentioned like using numpy only in this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrK8f7u7AQkb"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jtfBnQ4IhaJs"
      },
      "outputs": [],
      "source": [
        "X_moons,y_moons = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
        "X_train_moons, X_test_moons, y_train_moons, y_test_moons = train_test_split(X_moons, y_moons, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8dSqqFGoUXT",
        "outputId": "5e87fa41-b450-45b3-ccc0-6156be37f72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C: 10.0\n",
            "Kernel: rbf\n",
            "gamma: scale\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_combinations = brute_force_search(SVC, svm_params, \"Classification\",X_train_moons, y_train_moons, X_test_moons, y_test_moons )\n",
        "C, Kernel, gamma=best_combinations\n",
        "print(\"C:\", C)\n",
        "print(\"Kernel:\", Kernel)\n",
        "print(\"gamma:\", gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dvDPulNWsPxc"
      },
      "outputs": [],
      "source": [
        "\n",
        "house_data = fetch_california_housing(as_frame=True)\n",
        "X = house_data.data\n",
        "y = house_data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_scaler = StandardScaler()\n",
        "X_train = X_scaler.fit_transform(X_train)\n",
        "X_test = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D55J4nvcnjXs",
        "outputId": "ce55bf02-5538-479d-f0ca-e2fa29b49839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha: 100.0\n",
            "solver: svd\n"
          ]
        }
      ],
      "source": [
        "best_combinations = brute_force_search(Ridge, ridge_params, \"Regression\",X_train, y_train, X_test, y_test)\n",
        "alpha, solver=best_combinations\n",
        "print(\"alpha:\", alpha)\n",
        "print(\"solver:\", solver)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idp7p70AbP1y"
      },
      "source": [
        "## Task 5.2.2 - Simple TPE (BONUS)\n",
        "\n",
        "* Implement the Tree-Structured Parzen Estimator using `numpy` only. **(RESULT)**\n",
        "* Find decent hyperparameters for\n",
        "    - 1) An `SVM` model on the `two moons` problem. **(RESULT)**\n",
        "    - 2) A `LinearRegression` model with Ridge regularization on the `California Housing Dataset`. **(RESULT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGPkgi2BAYOd"
      },
      "source": [
        "# Building TPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eE67vRakbP1z"
      },
      "outputs": [],
      "source": [
        "import numbers\n",
        "class TPE:\n",
        "  def __init__(self, model, param_ranges, n_iterations, task, n_init_samples=5):\n",
        "    self.model = model\n",
        "    self.param_ranges = param_ranges\n",
        "    self.n_iterations = n_iterations\n",
        "    self.initsample={}\n",
        "    self.task=task\n",
        "    for param, values in param_ranges.items():\n",
        "\n",
        "        if (isinstance(values, (tuple)) and len(values) == 2):\n",
        "                self.initsample[param] = np.random.uniform(values[0], values[1], n_init_samples)\n",
        "        else:\n",
        "                self.initsample[param] = values\n",
        "\n",
        "    self.trials=[]\n",
        "\n",
        "  def fit(self, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "  def find_initialGoodBad(self):\n",
        "    self.param_names = list(self.initsample.keys())\n",
        "    param_values = list(self.initsample.values())\n",
        "\n",
        "    all_combinations = list(itertools.product(*param_values))\n",
        "\n",
        "    # all_combinations_lists = [list(t) for t in all_combinations]\n",
        "    l_x=[]\n",
        "    g_x=[]\n",
        "    paramdict={}\n",
        "    for combination in all_combinations:\n",
        "\n",
        "        for key, value in zip(self.param_names, combination):\n",
        "          paramdict[key]=value\n",
        "        mymodel= self.model(**paramdict)\n",
        "        mymodel.fit(self.X_train, self.y_train)\n",
        "        if self.task ==\"Classification\":\n",
        "          score = accuracy_score(self.y_test, mymodel.predict(self.X_test))\n",
        "        else:\n",
        "          score = mean_squared_error(self.y_test, mymodel.predict(self.X_test))\n",
        "        self.trials.append({\"params\": combination, \"score\": score})\n",
        "    scores = [list(d.values())[1] for d in self.trials]\n",
        "\n",
        "    self.threshold= np.quantile(scores, 0.2)\n",
        "    if self.task==\"Classification\":\n",
        "\n",
        "      for diction in self.trials:\n",
        "          if list(diction.values())[1] > self.threshold:\n",
        "                l_x.append(list(diction.values())[0])\n",
        "          else:\n",
        "                g_x.append(list(diction.values())[0])\n",
        "    else:\n",
        "      for diction in self.trials:\n",
        "          if list(diction.values())[1] < self.threshold:\n",
        "                l_x.append(list(diction.values())[0])\n",
        "          else:\n",
        "                g_x.append(list(diction.values())[0])\n",
        "\n",
        "    return l_x, g_x\n",
        "\n",
        "  def find_modeldistribution(self, l_x, g_x):\n",
        "\n",
        "       self.result = [[d[param] for d in l_x] for param in range(len(self.param_names))]\n",
        "       self.result2 = [[d[param] for d in g_x] for param in range(len(self.param_names))]\n",
        "       goodmean=[]\n",
        "       goodstd=[]\n",
        "       distcatperparametergood=[]\n",
        "       for param in self.result:\n",
        "        if isinstance(param[0], numbers.Number):\n",
        "          goodmean.append(np.mean(param))\n",
        "          goodstd.append(np.std(param))\n",
        "        else:\n",
        "          distpercat=[]\n",
        "          par=list(set(param))\n",
        "          for value in par:\n",
        "           count= param.count(value)\n",
        "           distpercat.append(count/len(param))\n",
        "          distcatperparametergood.append(distpercat)\n",
        "\n",
        "\n",
        "\n",
        "       return self.result, goodmean, goodstd, distcatperparametergood\n",
        "\n",
        "  def drawnewsample(self, distcatperparametergood, n_samples, goodmean, goodstd):\n",
        "    new_candidates = []\n",
        "    i=0\n",
        "    j=0\n",
        "    k=0\n",
        "    for param in self.result:\n",
        "      if isinstance(param[0], numbers.Number):\n",
        "        samples = np.random.normal(loc=goodmean[i], scale=goodstd[i], size=n_samples)\n",
        "        par=self.param_names[k]\n",
        "        lower_bound = self.param_ranges[par][0]\n",
        "        upper_bound = self.param_ranges[par][1]\n",
        "        samples = np.clip(samples, lower_bound, upper_bound)\n",
        "        new_candidates.append(samples)\n",
        "        i+=1\n",
        "      else:\n",
        "        par=list(set(param))\n",
        "        samples = np.random.choice(par, size=n_samples, p=distcatperparametergood[j])\n",
        "        j+=1\n",
        "        new_candidates.append(samples)\n",
        "      k+=1\n",
        "    return new_candidates\n",
        "\n",
        "  def kernel(self, u):\n",
        "    return 1 / np.sqrt(2 * np.pi) * np.exp(-1 / 2 * u * u)\n",
        "\n",
        "  def kde_single_point(self, history_data, query_value):\n",
        "    n = len(history_data)\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "\n",
        "    sigma = np.std(history_data)\n",
        "\n",
        "    if sigma == 0:\n",
        "        h = 0.1\n",
        "    else:\n",
        "        h = 1.06 * sigma * (n ** -0.2)\n",
        "\n",
        "    kernel_sum = 0\n",
        "    for i in range(n):\n",
        "        # u = (x - xi) / h\n",
        "        u = (query_value - history_data[i]) / h\n",
        "        kernel_sum += self.kernel(u)\n",
        "\n",
        "    density = kernel_sum / (n * h)\n",
        "\n",
        "    return density\n",
        "\n",
        "  def evaluate_new_candidates(self, new_candidates):\n",
        "\n",
        "    finallx=[]\n",
        "    finalgx=[]\n",
        "    for group in zip(*new_candidates):\n",
        "      elements = list(group)\n",
        "      lx=[]\n",
        "      gx=[]\n",
        "\n",
        "      for i, val in enumerate(elements):\n",
        "        if (isinstance(val, numbers.Number)):\n",
        "          kdegood=self.kde_single_point(self.result[i], val)\n",
        "          kdebad=self.kde_single_point(self.result2[i], val)\n",
        "          lx.append(kdegood)\n",
        "          gx.append(kdebad)\n",
        "\n",
        "        else:\n",
        "           count= self.result[i].count(val)\n",
        "           kdegood=count/len(self.result[i])\n",
        "           count= self.result2[i].count(val)\n",
        "           kdebad=count/len(self.result2[i])\n",
        "           lx.append(kdegood)\n",
        "           gx.append(kdebad)\n",
        "\n",
        "      finallx.append(np.prod(np.array(lx)))\n",
        "      finalgx.append(np.prod((np.array(gx))))\n",
        "\n",
        "    idx= np.argmax(np.array(finallx)/(np.array(finalgx) +1e-9))\n",
        "    paramdict={}\n",
        "    best_candidate = [param[idx] for param in new_candidates]\n",
        "    for key, value in zip(self.param_names, best_candidate):\n",
        "      paramdict[key]=value\n",
        "    mymodel= self.model(**paramdict)\n",
        "    mymodel.fit(self.X_train, self.y_train)\n",
        "    if self.task ==\"Classification\":\n",
        "        score = accuracy_score(self.y_test, mymodel.predict(self.X_test))\n",
        "    else:\n",
        "        score = mean_squared_error(self.y_test, mymodel.predict(self.X_test))\n",
        "    # current_values = [param[idx] for param in new_candidates]\n",
        "    self.trials.append({\"params\":best_candidate, \"score\": score})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def optimise(self):\n",
        "    l_x, g_x = self.find_initialGoodBad()\n",
        "\n",
        "    for i in range(self.n_iterations):\n",
        "      result, goodmean, goodstd, distcatperparametergood = self.find_modeldistribution(l_x, g_x)\n",
        "      new_candidates = self.drawnewsample(distcatperparametergood, 10, goodmean, goodstd)\n",
        "      self.evaluate_new_candidates(new_candidates)\n",
        "      if self.task==\"Classification\" and self.trials[-1]['score']>self.threshold:\n",
        "          l_x.append(self.trials[-1]['params'])\n",
        "      elif self.task==\"Classification\" and self.trials[-1]['score']<self.threshold:\n",
        "          g_x.append(self.trials[-1]['params'])\n",
        "      elif self.task==\"Regression\" and self.trials[-1]['score']<self.threshold:\n",
        "          l_x.append(self.trials[-1]['params'])\n",
        "      else:\n",
        "          g_x.append(self.trials[-1]['params'])\n",
        "    if self.task==\"Classification\":\n",
        "      best_trial = max(self.trials, key=lambda t: t[\"score\"])\n",
        "    else:\n",
        "      best_trial = min(self.trials, key=lambda t: t[\"score\"])\n",
        "    best_params = best_trial[\"params\"]\n",
        "    return best_params\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg82NmT27h5N"
      },
      "source": [
        "Assumption have been made in this implementation: if the parameter is continous, it will be passed as a tuple of 2 values namely the min and max values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTCd1OpqAbuO"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll4q6iUvbP1z",
        "outputId": "96a62dbb-b0d5-4f2c-eefc-58aa4890d338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C: 21.888615737517284\n",
            "Kernel: rbf\n",
            "gamma: scale\n"
          ]
        }
      ],
      "source": [
        "tpe=TPE(SVC, {\n",
        "    'C': (0.1, 100.0),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}, 100, \"Classification\")\n",
        "tpe.fit(X_train_moons, y_train_moons, X_test_moons, y_test_moons)\n",
        "best_params = tpe.optimise()\n",
        "C, Kernel, gamma=best_params\n",
        "print(\"C:\", C)\n",
        "print(\"Kernel:\", Kernel)\n",
        "print(\"gamma:\", gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAZ89Gjbkaz-",
        "outputId": "3cfee338-bdfb-457d-82e7-5fc39ca041fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha: 62.23286539411037\n",
            "solver: svd\n"
          ]
        }
      ],
      "source": [
        "tpe=TPE(Ridge, {\n",
        "    'alpha': (0.01, 100.0),\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr']\n",
        "}, 100, \"Regression\")\n",
        "tpe.fit(X_train, y_train, X_test, y_test)\n",
        "best_params = tpe.optimise()\n",
        "alpha, solver=best_params\n",
        "print(\"alpha:\", alpha)\n",
        "print(\"solver:\", solver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "62oyiqrPbP10",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Congratz, you made it! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToZD5cjfbP10"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pyforecast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
