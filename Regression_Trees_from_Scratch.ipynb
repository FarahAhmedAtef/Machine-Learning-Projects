{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T88mEE0WlVpg"
      },
      "source": [
        "## Task 6.1.1 - Regression Trees\n",
        "\n",
        "* Implement the Regression Tree Class from scratch using only `NumPy`. **(RESULT)**\n",
        "* Run your implementation on the synthetic regression dataset provided. **(RESULT)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2L1LBzY7lVph"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_regression_data(n_samples=1000, n_features=8, noise=0.1, random_state=42):\n",
        "    \"\"\"Generate synthetic regression data similar to California housing.\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    X = np.random.randn(n_samples, n_features)\n",
        "\n",
        "    # Create target with non-linear relationships\n",
        "    y = (2.5 * X[:, 0] +\n",
        "         1.8 * X[:, 1] ** 2 +\n",
        "         -1.2 * X[:, 2] * X[:, 3] +\n",
        "         0.5 * np.sin(5 * X[:, 4]) +\n",
        "         0.8 * X[:, 5] +\n",
        "         -0.3 * X[:, 6] ** 3 +\n",
        "         1.5 * X[:, 7])\n",
        "\n",
        "    # Add noise\n",
        "    y += noise * np.random.randn(n_samples)\n",
        "\n",
        "    # Scale to reasonable range\n",
        "    y = (y - y.min()) / (y.max() - y.min()) * 4 + 1\n",
        "\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_srHdl4JiGo"
      },
      "source": [
        "#Build Regression Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "To2CoPoClVph"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, feature, threshold, left, right):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "class RegressionTree:\n",
        "    \"\"\"A decision tree for regression using numpy.\"\"\"\n",
        "\n",
        "    def __init__(self,depth=5, minsamplesatnode=1):\n",
        "        self.depth = depth\n",
        "        self.minsamplesatnode=minsamplesatnode\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Build the regression tree.\"\"\"\n",
        "        self.contordiscrete={}\n",
        "        for i in range(X.shape[1]):\n",
        "            uniqpersample=np.unique(X[:,i])\n",
        "            ratiocontordiscrete=len(uniqpersample)/len(X[:,i])\n",
        "            if ratiocontordiscrete>=0.9:\n",
        "              self.contordiscrete[i]=\"Continous\"\n",
        "            else:\n",
        "              self.contordiscrete[i]=\"Discrete\"\n",
        "        self.rootnode = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        \"\"\"Recursively build the tree.\"\"\"\n",
        "        if depth < self.depth and len(X)>self.minsamplesatnode:\n",
        "            best_feature, best_threshold = self._find_best_split(X, y)\n",
        "            if best_feature is None or best_threshold is None:\n",
        "                return y.mean()\n",
        "            Xi = X[:, best_feature]\n",
        "            left_mask = Xi <= best_threshold\n",
        "            right_mask = Xi > best_threshold\n",
        "            y_left=y[left_mask]\n",
        "            y_right=y[right_mask]\n",
        "            X_left=X[left_mask]\n",
        "            X_right=X[right_mask]\n",
        "            depth+=1\n",
        "            left = self._build_tree(X_left,y_left,depth)\n",
        "            right = self._build_tree(X_right,y_right, depth)\n",
        "            return TreeNode(best_feature,best_threshold,left,right)\n",
        "        return y.mean()\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions for X.\"\"\"\n",
        "        y_pred=[]\n",
        "        for x in X:\n",
        "          res=self.rootnode\n",
        "\n",
        "          while isinstance(res, TreeNode):\n",
        "            if x[res.feature]<=res.threshold:\n",
        "              res=res.left\n",
        "              # print(\"left\")\n",
        "            else:\n",
        "              res=res.right\n",
        "              # print(\"right\")\n",
        "          y_pred.append(res)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "\n",
        "      featuremsepair={}\n",
        "\n",
        "      for i in range(X.shape[1]):\n",
        "        sorted_idx = np.argsort(X[:, i])\n",
        "        arr_sorted = X[sorted_idx, i]\n",
        "        y = y[sorted_idx]\n",
        "        X=X[sorted_idx, :]\n",
        "        mselist=[]\n",
        "        thresholdlist=[]\n",
        "        if self.contordiscrete[i]==\"Continous\":\n",
        "          lim=X.shape[0]-1\n",
        "        else:\n",
        "          uniquearr_sorted=np.unique(arr_sorted)\n",
        "          lim=len(uniquearr_sorted)\n",
        "        for j in range(lim):\n",
        "\n",
        "          if self.contordiscrete[i]==\"Continous\":\n",
        "            threshold=(arr_sorted[j]+arr_sorted[j+1])/2\n",
        "          else:\n",
        "            threshold=uniquearr_sorted[j]\n",
        "\n",
        "          Xi = X[:, i]\n",
        "          left_mask = Xi <= threshold\n",
        "          right_mask = Xi > threshold\n",
        "          y_left=y[left_mask]\n",
        "          y_right=y[right_mask]\n",
        "          X_left=X[left_mask]\n",
        "          X_right=X[right_mask]\n",
        "          if y_left.size == 0 or y_right.size == 0:\n",
        "              continue\n",
        "          y_left_mean=np.mean(y_left)\n",
        "          y_right_mean=np.mean(y_right)\n",
        "          mse_left=np.sum((y_left-y_left_mean)**2)\n",
        "          mse_right=np.sum((y_right-y_right_mean)**2)\n",
        "          mse_total=mse_left+mse_right\n",
        "          mselist.append(mse_total)\n",
        "          thresholdlist.append(threshold)\n",
        "        if len(mselist)==0:\n",
        "          continue\n",
        "        k=np.argmin(np.array(mselist))\n",
        "        featuremsepair[i]={\"mse\":mselist[k], \"threshold\":thresholdlist[k]}\n",
        "      if len(featuremsepair)==0:\n",
        "        return None, None\n",
        "      best_feature = min(featuremsepair, key=lambda i: featuremsepair[i][\"mse\"])\n",
        "\n",
        "      bestvalue = featuremsepair[best_feature]\n",
        "\n",
        "      return best_feature, bestvalue[\"threshold\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zfp3tw5qLmLW"
      },
      "outputs": [],
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    return sum((y_true - y_pred)**2)/len(y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw8UsEmTJnVz"
      },
      "source": [
        "#Test on synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruBfIxShlVpi",
        "outputId": "bdc19b13-b975-4847-b069-25fd89d43aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE 0.07233008392593654\n"
          ]
        }
      ],
      "source": [
        "X,y=generate_regression_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "tree=RegressionTree()\n",
        "tree.fit(X_train,y_train)\n",
        "y_pred=tree.predict(X_test)\n",
        "print(\"MSE\", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITAoppNrlVpi"
      },
      "source": [
        "## Task 6.1.2 - Bagging\n",
        "\n",
        "* Implement Bagging using only `NumPy`. **(RESULT)**\n",
        "* Compare the results between the bagged run of your `RegressionTree` class on the synthetic dataset. **(RESULT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh5ws1-1J2Ys"
      },
      "source": [
        "#Build Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jAlehOQjlVpi"
      },
      "outputs": [],
      "source": [
        "class BaggingRegressor:\n",
        "    \"\"\"Bagging ensemble for regression trees.\"\"\"\n",
        "\n",
        "    def __init__(self, bags, n_samples):\n",
        "        self.bags = bags\n",
        "        self.samples = n_samples\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      self.dict_bagged_trees={}\n",
        "      for i in range(self.bags):\n",
        "        bag_indices = np.random.choice(len(X), size=self.samples, replace=True)\n",
        "        bag_X = X[bag_indices]\n",
        "        bag_y = y[bag_indices]\n",
        "        tree = RegressionTree()\n",
        "        tree.fit(bag_X, bag_y)\n",
        "        self.dict_bagged_trees[i]=tree\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions by averaging all trees.\"\"\"\n",
        "        treepred=[]\n",
        "        for i in range(self.bags):\n",
        "          tree=self.dict_bagged_trees[i]\n",
        "          y_pred=tree.predict(X)\n",
        "          treepred.append(y_pred)\n",
        "        y_pred=np.mean(treepred,axis=0)\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erTftKFbKCco"
      },
      "source": [
        "# Test on different hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcUnpeSGlVpi",
        "outputId": "a25a90ca-a67f-4903-dddc-10f3d5f01395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE 0.055688133490828226\n"
          ]
        }
      ],
      "source": [
        "tree=BaggingRegressor(5,300)\n",
        "tree.fit(X_train,y_train)\n",
        "y_pred=tree.predict(X_test)\n",
        "print(\"MSE\", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xXXwbKEKIE7",
        "outputId": "c7500d64-f12d-4158-da14-e0f43ead8e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE 0.06489462319478362\n"
          ]
        }
      ],
      "source": [
        "tree=BaggingRegressor(3,250)\n",
        "tree.fit(X_train,y_train)\n",
        "y_pred=tree.predict(X_test)\n",
        "print(\"MSE\", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2L6_m0Nhhj"
      },
      "source": [
        "As you can see, the the bagged run has lower mse than the standard tree run which is expected. We tried at different hyperparameters and achieved better results compared to the standard tree at both combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "S3NDVTB-lVpi",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Congratz, you made it! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK3KiRQClVpj"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pyforecast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
